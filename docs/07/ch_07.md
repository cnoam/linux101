üëç

# Advanced Text Processing

In this chapter we will discuss two tools that allow for advanced manipulation of text in the linux shell environment.

`sed` is a stream editor for non-interactive text transformations, working line by line for substitutions and more. <br>
`awk` is a more powerful text processing language for structured data, splitting lines into fields and allowing actions based on patterns, ideal for data extraction and complex manipulation. Both are essential Linux tools often used together for text processing tasks.

## Stream EDitor (sed)
This program reads text from stdin, applies processing (from command line) and writes the result to stdout. 

The idea is powerful: you have a very big file (or endless text stream), and you need to do some editing in it before it goes to the next processing stage. Again, this is the idea of `filter programs` connected in a pipeline.

It is very complex, and here we only show a trivial use case:

"For the input stream, find and replace all occurrences of STRING1 with STRING2"

Example: `echo "I use Windows to clean windows in the knight" | sed -e "s/Windows/Linux/"`
-> `I use Linux to clean windows in the knight`

Explanation:

`-e` : execute the expression

`s` : substitute

`/pattern1/pattern2/` find `pattern1` and (in this case) substitute with `pattern2`

This operation is done for every line in the input stream/file.

There are whole [books](https://www.amazon.com/sed-awk-Dale-Dougherty/dp/1565922255) on sed, but we stop here.

> Questions you could ask:
>
> - can it be case insensitive?
> - what if "Windows" appears more than once in one line?
> - Can I use the found pattern  - e.g. "Windows95"
> - what are the syntax rules of defining the patterns?

<br>
<hr>
<br>

## AWK

Awk is a text processing tool built in 1977 in Bell labs. 
Surprisingly enough, it is still widely used today by many people for its simplicity and power. 

Awk is interpreted -> slow for large inputs.<br>
Use it for quick and dirty processing of texts, or as part of scripts. This will usually be part of a pipeline (e.g. find | awk | sort ).

Examples taken from https://en.wikibooks.org/wiki/An_Awk_Primer


Awk can be used with command line args "one line program" or with a program file.

An Awk program has the general form:
```
BEGIN { initializations }  search pattern 1 { program actions } search pattern 2 { program actions } ... END { final actions }
```
Each part is optional if it is not needed.

Download the [sample file](../assets/07/coins.txt) and run `$ awk '/gold/' coins.txt`

‚ùî Why  no "{program actions}"?

The above show the "one liner" usage: <br>
`awk search-pattern { program actions }`

We can add conditions:<br>
`awk '{if ($3 < 1980) print $3, "....",$5,$6,$7,$8}' coins.txt`

In awk, everything is a string, but if the string can be understood as number, it is possible to perform number operations on it.

### BEGIN and END

`awk 'END {print NR,"coins"}' coins.txt`

You can add sections that will be done before and after the lines are read from the input.

```
# (in a single line. folded here for brevity)
awk 'BEGIN { initializations }
    search pattern 1 { program actions }
    search pattern 2 { program actions }
    ...
    END { final actions }' input file
```

### Variables
User defined variables are not declared. They are defaulting to empty string or 0.
`{ounces += $2}` will define `ounces`, set it to 0 and add value of field 2

‚ùî Is $1 the first or second field? (i.e. zero based indexing or not)

A variable can be a scalar or array.<br>
There are builtin variables such as

**NR**: Keeps a current count of the number of input records<br>
**NF**: number of fields within the current input record<br>
**FS**: the field separator character used to divide fields on the input line<br>
**RS**: Record separator    ‚Üê a record can span MORE THAN ONE LINE!

`echo -e "one two three \n a b c d e f" | awk '{print NF}'`

will print `3 6` : three fields in first line, and 6 in the second

### Search Patterns
`awk /regular expression/ [...]`

The regular expression (regex) is POSIX Extended Regular Expressions. It is similar to python's variant.

If empty, it matches everything.

### Awk program

If there is more than one statement, write them in a file:

`awk -f awk program datafile`

Awk can also read from stdin (important for pipeline!) 

`awk -f awk program < datafile`

### Exercise
Based on the data in coins.txt:

- how many gold pieces?
- how many silver pieces?
- weight and value of each? (assume gold is 485 [Dinar/gram] and silver is 16 [Dinar/gram]
)

See the [answer](../assets/07/summing.awk) if you are stuck.


## Is that it?
There is more to awk! 

    ‚Ä¢ Arrays
    ‚Ä¢ Functions
    ‚Ä¢ Control structures (if, while, break...)
    ‚Ä¢ Output formats
    ‚Ä¢ Redirection to files
    ‚Ä¢ Debugging awk programs
    ‚Ä¢ Extensions to the language

But with today's availability of AI, should we invest in learning awk, or just ask the AI to create python/awk script for us?

obviously, if you are offline/no-ai-status, you must know what to do.

And even when online, use awk/sed/tr to do simple tasks. it is good to know you don't have to write a python script just to cut some columns and sum them.


## Examples (using both awk and sed)

Given the file "Alice_book", prepare it for processing. You can find it [here](../assets/07/alice.txt)


**convert all to lower case and remove punctuation marks and create a new book called Alice_book_new**

```
awk '{print tolower($0)}' Alice_book | awk '{ gsub(/[[:punct:]]/, "", $0) } 1;' > Alice_book_new
```


**remove empty lines**
`sed -i '/^[[:space:]]*$/d' Alice_book_new`

**remove leading spaces and tabs from each line**
`sed -i "s/^[ \t]*//" Alice_book_new`

<br>

# Summary
This chapter provides an overview of two powerful, complementary text-processing utilities in the Linux shell: sed, a non-interactive stream editor designed for line-by-line transformations such as substitutions and deletions, and awk, a pattern-action language well suited to structured data extraction and more complex scripting. It introduces basic sed usage (e.g., s/old/new/ for find-and-replace), then explores awk‚Äôs one-liner and program-file formats, its built-in variables (like NR, NF, FS, RS),  and its support for conditions, loops, and user-defined variables.